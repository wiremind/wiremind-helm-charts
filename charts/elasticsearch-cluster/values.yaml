nameOverride: ""
fullnameOverride: ""

# To define common settings, it may be useful to use YAML anchors to use the same
# base settings for all node types (data + master) + ingest
es-defaults: &defaults
  # Change me, and change urls using elasticsearch below
  clusterName: "my-elasticsearch-cluster"

# The data nodes
es-data-hot:
  <<: *defaults
  nodeGroup: "data-hot"
  enabled: true
  # esConfig:
  #   elasticsearch.yml: |
  #     node:
  #       attr:
  #         data: hot
  #     xpack:
  #       security:
  #         enabled: false
  #         transport:
  #           ssl:
  #             enabled: false
  #         http:
  #           ssl:
  #             enabled: false
  roles:
    master: "false"
    ingest: "true"
    data: "true"
  replicas: 1
  # esJavaOpts: "-Xmx1g  -Xms1g"
  # resources:
  #   requests:
  #     cpu: "10m"
  #     memory: "128Mi"
  #   limits:
  #     memory: "56Gi"
  #     cpu: 15
  volumeClaimTemplate:
    resources:
      requests:
        storage: 1Gi
  ingress:
    enabled: false
    # path: /
    # hosts:
    #   - elasticsearch.setme.org
    # tls:
    #   - secretName: elasticsearch.setme.org-tls
    #     hosts:
    #       - elasticsearch.setme.org

es-data-warm:
  <<: *defaults
  nodeGroup: "data-warm"
  enabled: false
  # esConfig:
  #   elasticsearch.yml: |
  #     node:
  #       attr:
  #         data: warm
  #     xpack:
  #       security:
  #         enabled: false
  #         transport:
  #           ssl:
  #             enabled: false
  #         http:
  #           ssl:
  #             enabled: false
  roles:
    master: "false"
    ingest: "false"
    data: "true"
  replicas: 1
  esJavaOpts: "-Xmx1g  -Xms1g"
  # resources:
  #   requests:
  #     memory: "128Mi"
  #     cpu: "10m"
  #   limits:
  #     memory: "18Gi"
  #     cpu: 15
  volumeClaimTemplate:
    resources:
      requests:
        storage: 1Gi

es-data-cold:
  <<: *defaults
  nodeGroup: "data-cold"
  enabled: false
  # esConfig:
  #   elasticsearch.yml: |
  #     node:
  #       attr:
  #         data: cold
  #     xpack:
  #       security:
  #         enabled: false
  #         transport:
  #           ssl:
  #             enabled: false
  #         http:
  #           ssl:
  #             enabled: false
  roles:
    master: "false"
    ingest: "false"
    data: "true"
  replicas: 1
  # esJavaOpts: "-Xmx1g  -Xms1g"
  # resources:
  #   requests:
  #     memory: "128Mi"
  #     cpu: "10m"
  #   limits:
  #     memory: 16Gi
  #     cpu: 6
  volumeClaimTemplate:
    resources:
      requests:
        storage: 1Gi

# The ingest (a.k.a client) nodes
es-ingest:
  <<: *defaults
  nodeGroup: "master"
  enabled: false
  roles:
    master: "false"
    ingest: "true"
    data: "false"
  replicas: 1
  # esJavaOpts: "-Xmx1g  -Xms1g"
  # resources:
  #   requests:
  #     memory: 128Mi
  #     cpu: "10m"
  #   limits:
  #     memory: "1Gi"
  #     cpu: "2"
  volumeClaimTemplate:
    resources:
      requests:
        storage: 1Gi

# The master nodes
es-master:
  <<: *defaults
  nodeGroup: "master"
  enabled: true
  # esConfig:
  #   elasticsearch.yml: |
  #     xpack:
  #       security:
  #         enabled: false
  #         transport:
  #           ssl:
  #             enabled: false
  #         http:
  #           ssl:
  #             enabled: false
  roles:
    master: "true"
    ingest: "false"
    data: "false"
  # esJavaOpts: "-Xms128m -Xmx128m"
  #  resources:
  #    requests:
  #      memory: 128Mi
  #      cpu: "10m"
  #    limits:
  #      memory: "1Gi"
  #      cpu: "2"
  volumeClaimTemplate:
    resources:
      requests:
        storage: 1Gi

# Creates a default indexLifecycleManagement policy
# Note: you'll have to manage index templates so that your indices point to this ILM.
indexLifecycleManagement:
  enabled: false
  # Name of the policy to create
  name: wiremind
  # Ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/_timing.html
  warm:
    minAge: 8d
  cold:
    minAge: 31d
  delete:
    enabled: false
    minAge: 90d
  # priorityClassName: my-priority-class

## Configure a s3 backup repository and snapshot policy on it
## Currently only supports s3 and with a lot of snapshot policy hardcoded, to be generalized
backup:
  enabled: false
  accessKey: setme
  secretKey: setme
  s3BucketName: setme
  # https://www.elastic.co/guide/en/elasticsearch/reference/7.x/getting-started-snapshot-lifecycle-management.html for more details.
  backupSchedule: "0 30 1 * * ?"
  backupNameExpression: "<daily-snap-{now/d}>"
  backupExpireAfter: "30d"
  backupMinCount: 5
  backupMaxCount: 50
  ## Set priority class name for setting up ES regarding related object storage repository
  # priorityClassName:

kibana:
  enabled: false
  # Change me
  elasticsearchHosts: http://my-elasticsearch-hot-url:9200
  resources:
    limits:
      cpu: 2
      memory: 2Gi
    requests:
      cpu: 100m
      memory: 1000Mi
  kibanaConfig:
    kibana.yml: |
      server.name: kibana
      server.host: "0"
      elasticsearch.requestTimeout: 180000
  ingress:
    enabled: false
    # hosts:
    #   - host: kibana.setme.org
    #     paths:
    #       - path: /
    # tls:
    #   - hosts:
    #       - kibana.setme.org
    #     secretName: kibana.setme.org-tls
  readinessProbe:
    successThreshold: 1

prometheus-elasticsearch-exporter:
  enabled: true
  es:
    # Change me
    uri: http://my-elasticsearch-master-url:9200
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 2
      memory: 128Mi
  serviceMonitor:
    enabled: false
  prometheusRule:
    enabled: false
    rules:
      - alert: ESNoBackup
        # Note that it will fire only if backup repo exists, so only for prod
        expr: |
          (
            time()
            -
            elasticsearch_snapshot_stats_snapshot_end_time_timestamp{service="{{ template "elasticsearch-exporter.fullname" . }}", state="SUCCESS"}
          )
          / 3600 / 24 > 2.5
        labels:
          severity: warning
        annotations:
          summary: |
            No successful {{ "{{ $labels.instance }}" }} Elasticsearch backup for {{ "{{ $value }}" }} days
          description: No recent Elasticsearch backup
      - alert: ESClusterStatusRED
        expr: |
          elasticsearch_cluster_health_status{color="red", service="{{ template "elasticsearch-exporter.fullname" . }}"} == 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Cluster health status is RED"
          description: 'Cluster {{ "{{ $labels.cluster }}" }} health status is RED'
      - alert: ESClusteStatusYELLOW
        expr: |
          elasticsearch_cluster_health_status{color="yellow", service="{{ template "elasticsearch-exporter.fullname" . }}"} == 1
        for: 20m
        labels:
          severity: high
        annotations:
          summary: "Cluster health status is YELLOW"
          description: 'Cluster {{ "{{ $labels.cluster }}" }} health status is YELLOW'

      # Report any rejected request.
      - alert: ESBulkRequestsRejection
        expr: |
          irate(elasticsearch_thread_pool_rejected_count{service="{{ template "elasticsearch-exporter.fullname" . }}"}[1m]) > 0
        for: 1s
        labels:
          severity: high
        annotations:
          summary: "Elasticsearch Bulk Query Rejection"
          description: |
            'Bulk Rejection at {{ "{{ $labels.name }}" }} node in {{ "{{ $labels.cluster }}" }} cluster'

      - alert: ESJVMHeapHigh
        expr: |
          sum by (cluster, name, namespace)
            (elasticsearch_jvm_memory_used_bytes{area="heap", service="{{ template "elasticsearch-exporter.fullname" . }}"}
            /
            elasticsearch_jvm_memory_max_bytes{area="heap", service="{{ template "elasticsearch-exporter.fullname" . }}"}
          )
          > 75
        for: 5m
        labels:
          severity: alert
        annotations:
          summary: "JVM Heap usage on the node is high"
          description: |
            'JVM Heap usage on the node {{ "{{ $labels.node }}" }} in {{ "{{ $labels.cluster }}" }} cluster is {{ "{{ $value }}" }}%. There might be long running GCs now.'

cerebro:
  enabled: false
  ingress:
    enabled: false
  deployment:
    readinessProbe:
      enabled: false
  config:
    basePath: "/"
    restHistorySize: 50
    hosts:
      - name: elasticsearch-cluster
        # Change me
        host: http://my-elasticsearch-hot-url:9200
